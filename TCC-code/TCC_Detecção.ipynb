{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##GIT Repository"
      ],
      "metadata": {
        "id": "v561_qPlWxjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0mJxO2RSGCs",
        "outputId": "f13fb2ae-e2b8-47da-9e2f-88653d75c38e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_url = 'https://github.com/gistairc/MUSIC4P3.git'\n",
        "!git clone $repo_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BITsxsG2ynC",
        "outputId": "cf8b3c9b-892f-4b6e-d651-7fada406afd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MUSIC4P3'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Total 123 (delta 0), reused 0 (delta 0), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (123/123), 314.03 KiB | 3.27 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Process"
      ],
      "metadata": {
        "id": "cjJuZrBaYCgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "-cpY47B2YPMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "41NrOOlkYOIq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_train = '/content/drive/MyDrive/TCC - Gabriela Alves Marinho/train'\n",
        "folder_mask = '/content/drive/MyDrive/TCC - Gabriela Alves Marinho/masks'\n",
        "folder_test = '/content/drive/MyDrive/TCC - Gabriela Alves Marinho/test'\n",
        "\n",
        "train_files = os.listdir(folder_train)\n",
        "mask_files = os.listdir(folder_mask)\n",
        "\n",
        "train_files.sort()\n",
        "mask_files.sort()"
      ],
      "metadata": {
        "id": "5_1d31oBYLpS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply mask on train image to create the labels"
      ],
      "metadata": {
        "id": "2_BbHXRDzdiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "\n",
        "for mask_file in mask_files:\n",
        "    mask_image = cv2.imread(os.path.join(folder_mask, mask_file))\n",
        "\n",
        "    green = np.array([138, 164, 105])\n",
        "    pink = np.array([190, 98, 130])\n",
        "    tolerancy = 70\n",
        "\n",
        "    # Verify if the image contains pink(erosion)\n",
        "    is_erosion = np.any(np.all(np.abs(mask_image - pink) < tolerancy, axis=-1))\n",
        "\n",
        "\n",
        "    # Add label\n",
        "    labels.append(1 if is_erosion else 0)"
      ],
      "metadata": {
        "id": "ISJNh496Yhyo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Separação da base de treino em treino e teste"
      ],
      "metadata": {
        "id": "pq_wswLkMFFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine as imagens e os rótulos em uma lista\n",
        "combined_data = list(zip(train_files, labels))\n",
        "train_data, test_data = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separe os dados de treino e validação novamente\n",
        "train_files, train_labels = zip(*train_data)\n",
        "test_files, test_labels = zip(*test_data)"
      ],
      "metadata": {
        "id": "yUG7MhL8L6T0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_data)\n",
        "print(len(train_files))\n",
        "print(len(test_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORlaRFPFzcQv",
        "outputId": "b30d68dd-c6b8-4bc6-ee44-db8dd9d4abf2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('10.jpg', 0), ('100.jpg', 1), ('101.jpg', 1), ('102.jpg', 0), ('103.jpg', 1), ('104.jpg', 1), ('105.jpg', 1), ('106.jpg', 1), ('107.jpg', 1), ('108.jpg', 1), ('109.jpg', 1), ('11.jpg', 1), ('110.jpg', 1), ('111.jpg', 1), ('112.jpg', 1), ('113.jpg', 1), ('114.jpg', 1), ('115.jpg', 1), ('116.jpg', 1), ('117.jpg', 1), ('118.jpg', 1), ('119.jpg', 1), ('12.jpg', 1), ('120.jpg', 1), ('121.jpg', 1), ('122.jpg', 1), ('123.jpg', 1), ('124.jpg', 1), ('125.jpg', 1), ('126.jpg', 1), ('127.jpg', 1), ('128.jpg', 1), ('129.jpg', 1), ('13.jpg', 1), ('130.jpg', 0), ('131.jpg', 1), ('132.jpg', 1), ('133.jpg', 1), ('134.jpg', 1), ('135.jpg', 1), ('136.jpg', 1), ('137.jpg', 1), ('138.jpg', 1), ('139.jpg', 1), ('14.jpg', 1), ('140.jpg', 1), ('141.jpg', 1), ('142.jpg', 1), ('143.jpg', 1), ('144.jpg', 0), ('145.jpg', 1), ('146.jpg', 0), ('147.jpg', 1), ('148.jpg', 1), ('149.jpg', 1), ('15.jpg', 1), ('150.jpg', 1), ('151.jpg', 1), ('152.jpg', 1), ('153.jpg', 1), ('154.jpg', 1), ('155.jpg', 1), ('156.jpg', 1), ('157.jpg', 1), ('158.jpg', 1), ('159.jpg', 1), ('16.jpg', 1), ('160.jpg', 1), ('161.jpg', 1), ('162.jpg', 1), ('163.jpg', 1), ('164.jpg', 1), ('165.jpg', 1), ('166.jpg', 1), ('167.jpg', 1), ('168.jpg', 1), ('169.jpg', 1), ('17.jpg', 1), ('170.jpg', 1), ('171.jpg', 1), ('172.jpg', 1), ('173.jpg', 1), ('174.jpg', 1), ('175.jpg', 1), ('176.jpg', 1), ('177.jpg', 1), ('178.jpg', 1), ('179.jpg', 1), ('18.jpg', 1), ('180.jpg', 1), ('181.jpg', 1), ('182.jpg', 1), ('183.jpg', 1), ('184.jpg', 1), ('185.jpg', 1), ('186.jpg', 1), ('187.jpg', 1), ('188.jpg', 1), ('189.jpg', 1), ('19.jpg', 1), ('190.jpg', 1), ('191.jpg', 1), ('192.jpg', 1), ('193.jpg', 1), ('194.jpg', 1), ('195.jpg', 1), ('196.jpg', 1), ('197.jpg', 1), ('198.jpg', 1), ('199.jpg', 1), ('2.jpg', 1), ('20.jpg', 1), ('200.jpg', 1), ('201.jpg', 1), ('202.jpg', 1), ('203.jpg', 1), ('204.jpg', 1), ('205.jpg', 1), ('206.jpg', 1), ('207.jpg', 1), ('208.jpg', 1), ('209.jpg', 1), ('21.jpg', 1), ('210.jpg', 1), ('211.jpg', 1), ('212.jpg', 1), ('213.jpg', 1), ('214.jpg', 1), ('215.jpg', 1), ('216.jpg', 1), ('217.jpg', 1), ('218.jpg', 1), ('219.jpg', 1), ('22.jpg', 1), ('220.jpg', 1), ('221.jpg', 1), ('222.jpg', 1), ('223.jpg', 1), ('224.jpg', 1), ('225.jpg', 1), ('226.jpg', 1), ('227.jpg', 1), ('228.jpg', 1), ('229.jpg', 0), ('23.jpg', 1), ('230.jpg', 0), ('231.jpg', 1), ('232.jpg', 1), ('233.jpg', 1), ('234.jpg', 1), ('235.jpg', 1), ('236.jpg', 0), ('237.jpg', 1), ('238.jpg', 1), ('239.jpg', 1), ('24.jpg', 1), ('240.jpg', 1), ('241.jpg', 1), ('242.jpg', 1), ('243.jpg', 1), ('244.jpg', 1), ('245.jpg', 1), ('246.jpg', 1), ('247.jpg', 1), ('248.jpg', 1), ('249.jpg', 1), ('25.jpg', 1), ('250.jpg', 1), ('251.jpg', 1), ('252.jpg', 1), ('253.jpg', 1), ('254.jpg', 1), ('255.jpg', 1), ('256.jpg', 1), ('257.jpg', 1), ('258.jpg', 1), ('259.jpg', 1), ('26.jpg', 1), ('260.jpg', 1), ('261.jpg', 1), ('262.jpg', 1), ('263.jpg', 1), ('264.jpg', 1), ('265.jpg', 1), ('266.jpg', 1), ('267.jpg', 1), ('268.jpg', 1), ('269.jpg', 1), ('27.jpg', 1), ('270.jpg', 0), ('271.jpg', 1), ('272.jpg', 1), ('273.jpg', 1), ('274.jpg', 1), ('275.jpg', 1), ('276.jpg', 1), ('277.jpg', 1), ('278.jpg', 1), ('279.jpg', 1), ('28.jpg', 1), ('280.jpg', 1), ('281.jpg', 1), ('282.jpg', 1), ('283.jpg', 1), ('284.jpg', 1), ('285.jpg', 1), ('286.jpg', 1), ('287.jpg', 1), ('288.jpg', 1), ('289.jpg', 1), ('29.jpg', 1), ('290.jpg', 1), ('291.jpg', 1), ('292.jpg', 1), ('293.jpg', 0), ('294.jpg', 1), ('295.jpg', 1), ('296.jpg', 1), ('297.jpg', 1), ('298.jpg', 1), ('299.jpg', 1), ('3.jpg', 1), ('30.jpg', 1), ('300.jpg', 1), ('301.jpg', 1), ('302.jpg', 1), ('303.jpg', 1), ('304.jpg', 1), ('305.jpg', 1), ('306.jpg', 1), ('307.jpg', 1), ('308.jpg', 1), ('309.jpg', 1), ('31.jpg', 1), ('310.jpg', 1), ('311.jpg', 1), ('312.jpg', 1), ('313.jpg', 1), ('314.jpg', 1), ('315.jpg', 1), ('316.jpg', 1), ('317.jpg', 1), ('318.jpg', 1), ('319.jpg', 1), ('32.jpg', 1), ('320.jpg', 1), ('321.jpg', 1), ('322.jpg', 1), ('323.jpg', 1), ('324.jpg', 1), ('325.jpg', 1), ('326.jpg', 1), ('327.jpg', 1), ('328.jpg', 1), ('329.jpg', 1), ('33.jpg', 1), ('330.jpg', 1), ('331.jpg', 0), ('332.jpg', 1), ('333.jpg', 1), ('334.jpg', 1), ('335.jpg', 1), ('336.jpg', 1), ('337.jpg', 1), ('338.jpg', 1), ('339.jpg', 1), ('34.jpg', 1), ('340.jpg', 1), ('341.jpg', 1), ('342.jpg', 1), ('343.jpg', 1), ('344.jpg', 1), ('345.jpg', 1), ('346.jpg', 1), ('347.jpg', 1), ('348.jpg', 1), ('349.jpg', 1), ('35.jpg', 1), ('350.jpg', 1), ('351.jpg', 1), ('352.jpg', 1), ('353.jpg', 1), ('354.jpg', 1), ('355.jpg', 1), ('356.jpg', 1), ('357.jpg', 1), ('358.jpg', 1), ('359.jpg', 1), ('36.jpg', 1), ('360.jpg', 1), ('361.jpg', 1), ('362.jpg', 1), ('363.jpg', 0), ('364.jpg', 1), ('365.jpg', 1), ('366.jpg', 1), ('367.jpg', 1), ('368.jpg', 1), ('369.jpg', 1), ('37.jpg', 1), ('370.jpg', 1), ('371.jpg', 1), ('372.jpg', 1), ('373.jpg', 1), ('374.jpg', 1), ('375.jpg', 1), ('376.jpg', 1), ('377.jpg', 1), ('378.jpg', 1), ('379.jpg', 1), ('38.jpg', 1), ('380.jpg', 1), ('381.jpg', 1), ('382.jpg', 1), ('383.jpg', 1), ('384.jpg', 1), ('385.jpg', 1), ('386.jpg', 1), ('387.jpg', 1), ('388.jpg', 1), ('389.jpg', 1), ('39.jpg', 1), ('390.jpg', 1), ('391.jpg', 1), ('392.jpg', 1), ('393.jpg', 1), ('394.jpg', 1), ('395.jpg', 1), ('396.jpg', 1), ('397.jpg', 1), ('398.jpg', 1), ('399.jpg', 1), ('4.jpg', 1), ('40.jpg', 1), ('400.jpg', 1), ('401.jpg', 1), ('402.jpg', 1), ('403.jpg', 1), ('404.jpg', 1), ('405.jpg', 1), ('406.jpg', 1), ('407.jpg', 1), ('408.jpg', 1), ('409.jpg', 1), ('41.jpg', 1), ('410.jpg', 1), ('411.jpg', 1), ('412.jpg', 1), ('413.jpg', 1), ('414.jpg', 1), ('415.jpg', 1), ('416.jpg', 1), ('417.jpg', 1), ('418.jpg', 1), ('419.jpg', 1), ('42.jpg', 1), ('420.jpg', 1), ('421.jpg', 1), ('422.jpg', 0), ('423.jpg', 1), ('424.jpg', 1), ('425.jpg', 1), ('426.jpg', 1), ('427.jpg', 1), ('428.jpg', 1), ('429.jpg', 1), ('43.jpg', 1), ('430.jpg', 1), ('431.jpg', 1), ('432.jpg', 1), ('433.jpg', 1), ('434.jpg', 1), ('435.jpg', 1), ('436.jpg', 1), ('437.jpg', 1), ('438.jpg', 1), ('439.jpg', 1), ('44.jpg', 1), ('440.jpg', 1), ('441.jpg', 1), ('442.jpg', 1), ('443.jpg', 1), ('444.jpg', 1), ('445.jpg', 1), ('446.jpg', 1), ('447.jpg', 1), ('448.jpg', 1), ('449.jpg', 1), ('45.jpg', 1), ('450.jpg', 1), ('451.jpg', 1), ('452.jpg', 1), ('453.jpg', 1), ('454.jpg', 1), ('455.jpg', 0), ('456.jpg', 1), ('457.jpg', 1), ('458.jpg', 1), ('459.jpg', 1), ('46.jpg', 0), ('460.jpg', 1), ('461.jpg', 1), ('462.jpg', 1), ('463.jpg', 1), ('464.jpg', 1), ('465.jpg', 1), ('466.jpg', 1), ('467.jpg', 0), ('468.jpg', 0), ('469.jpg', 1), ('47.jpg', 1), ('470.jpg', 1), ('471.jpg', 1), ('472.jpg', 1), ('473.jpg', 1), ('474.jpg', 1), ('475.jpg', 0), ('476.jpg', 1), ('477.jpg', 1), ('478.jpg', 1), ('479.jpg', 1), ('48.jpg', 1), ('480.jpg', 0), ('481.jpg', 1), ('482.jpg', 1), ('483.jpg', 1), ('484.jpg', 1), ('485.jpg', 1), ('486.jpg', 1), ('487.jpg', 1), ('488.jpg', 1), ('489.jpg', 1), ('49.jpg', 1), ('490.jpg', 1), ('491.jpg', 0), ('492.jpg', 1), ('493.jpg', 1), ('5.jpg', 1), ('50.jpg', 1), ('51.jpg', 1), ('52.jpg', 1), ('53.jpg', 1), ('54.jpg', 1), ('55.jpg', 1), ('56.jpg', 1), ('57.jpg', 1), ('58.jpg', 1), ('59.jpg', 1), ('6.jpg', 1), ('60.jpg', 1), ('61.jpg', 1), ('62.jpg', 1), ('63.jpg', 1), ('64.jpg', 1), ('65.jpg', 1), ('66.jpg', 1), ('67.jpg', 1), ('68.jpg', 1), ('69.jpg', 1), ('7.jpg', 1), ('70.jpg', 1), ('71.jpg', 1), ('72.jpg', 1), ('73.jpg', 1), ('74.jpg', 1), ('75.jpg', 1), ('76.jpg', 1), ('77.jpg', 1), ('78.jpg', 1), ('79.jpg', 1), ('8.jpg', 1), ('80.jpg', 0), ('81.jpg', 1), ('82.jpg', 1), ('83.jpg', 1), ('84.jpg', 1), ('85.jpg', 1), ('86.jpg', 1), ('87.jpg', 1), ('88.jpg', 1), ('89.jpg', 1), ('9.jpg', 1), ('90.jpg', 1), ('91.jpg', 1), ('92.jpg', 1), ('93.jpg', 1), ('94.jpg', 1), ('95.jpg', 1), ('96.jpg', 1), ('97.jpg', 1), ('98.jpg', 1), ('99.jpg', 1)]\n",
            "393\n",
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregue os dados de treino e teste\n",
        "train_data = []\n",
        "for train_file, label in zip(train_files, train_labels):\n",
        "    train_image = cv2.imread(os.path.join(folder_train, train_file))\n",
        "    train_data.append((train_image, label))\n",
        "\n",
        "test_data = []\n",
        "for test_file in test_files:\n",
        "    test_image = cv2.imread(os.path.join(folder_train, test_file))\n",
        "    test_data.append(test_image)"
      ],
      "metadata": {
        "id": "epgomKa-aJmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Application"
      ],
      "metadata": {
        "id": "Vb4V_AmAW5s9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Installs"
      ],
      "metadata": {
        "id": "a4_w8YYqXt6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chainer"
      ],
      "metadata": {
        "id": "mycxLjUIXtJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "-6SmSon7XI7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import chainer\n",
        "from chainer import Function, gradient_check, Variable, optimizers, utils\n",
        "from chainer import Link, Chain, ChainList\n",
        "from chainer.training.extensions import Evaluator\n",
        "\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer.datasets import LabeledImageDataset\n",
        "from chainer import datasets"
      ],
      "metadata": {
        "id": "r3hE8pl9XHwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data"
      ],
      "metadata": {
        "id": "UtGC4gOBxjBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LabeledImageDataset(chainer.dataset.DatasetMixin):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def get_example(self, i):\n",
        "        image, label = self.data[i]\n",
        "\n",
        "        # Convert image data to float and normalize to the range [0, 1]\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "\n",
        "        return image.transpose(2, 0, 1), label"
      ],
      "metadata": {
        "id": "Zb8kEodSySIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LabeledImageDataset(train_data)"
      ],
      "metadata": {
        "id": "IDVcLQGzlSh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Class for CNN"
      ],
      "metadata": {
        "id": "OOZj6W6eXPuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DetectCNN(chainer.Chain):\n",
        "    insize = 16\n",
        "    def __init__(self):\n",
        "      super(DetectCNN, self).__init__(\n",
        "            conv1=L.Convolution2D(3, 32, 3, stride=1, pad=1),  # Adjusting padding to maintain spatial dimensions\n",
        "            bn1=L.BatchNormalization(32),\n",
        "            conv2=L.Convolution2D(32, 64, 3, stride=1, pad=1),  # Increasing the number of filters and adjusting padding\n",
        "            bn2=L.BatchNormalization(64),\n",
        "            conv3=L.Convolution2D(64, 128, 3, stride=1, pad=1),  # Increasing the number of filters and adjusting padding\n",
        "            bn3=L.BatchNormalization(128),\n",
        "            fcl=L.Linear(None, 2),  # Adjusting the size of the linear layer\n",
        "        )\n",
        "      self.train = True,\n",
        "\n",
        "    def __call__(self, x, t=None):\n",
        "            h = self.conv1(x)\n",
        "            h = F.relu(h)\n",
        "            h = F.max_pooling_2d(h, ksize=2, stride=2)  # Adding max pooling to reduce the spatial dimensions\n",
        "            h = self.bn1(h)\n",
        "\n",
        "            h = self.conv2(h)\n",
        "            h = F.relu(h)\n",
        "            h = F.max_pooling_2d(h, ksize=2, stride=2)  # Adding max pooling\n",
        "            h = self.bn2(h)\n",
        "\n",
        "            h = self.conv3(h)\n",
        "            h = F.relu(h)\n",
        "            h = F.max_pooling_2d(h, ksize=2, stride=2)  # Adding max pooling\n",
        "            h = self.bn3(h)\n",
        "\n",
        "            h = F.average_pooling_2d(h, ksize=h.shape[2:])\n",
        "\n",
        "            h = self.fcl(h)\n",
        "            h = F.dropout(h)\n",
        "\n",
        "            if t is not None:\n",
        "                # Durante o treinamento, calcule a entropia cruzada softmax\n",
        "                self.pred = h\n",
        "                self.loss = F.softmax_cross_entropy(h, t)\n",
        "                self.accuracy = F.accuracy(self.pred, t)\n",
        "                chainer.report({'loss': self.loss, 'accuracy': self.accuracy}, self)\n",
        "                return self.loss\n",
        "            else:\n",
        "                # Durante a inferência, retorne as probabilidades diretamente\n",
        "                self.pred = F.softmax(h)\n",
        "                return self.pred"
      ],
      "metadata": {
        "id": "8-AGt9omXTPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizers"
      ],
      "metadata": {
        "id": "cYYhS8eTaZ9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chainer import optimizers\n",
        "\n",
        "model = DetectCNN()\n",
        "model.to_gpu()\n",
        "optimizer = chainer.optimizers.Adam()\n",
        "optimizer.setup(model)"
      ],
      "metadata": {
        "id": "XoKgUzsmeLeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Iterator"
      ],
      "metadata": {
        "id": "69KTNwB01qIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chainer import iterators\n",
        "from chainer.training import StandardUpdater, Trainer\n",
        "from chainer.training.extensions import LogReport, PrintReport\n",
        "\n",
        "batch_size = 32\n",
        "train_iter = iterators.MultiprocessIterator(train_dataset, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "G7BVloIX1pxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training model"
      ],
      "metadata": {
        "id": "lF35oKza13sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updater = StandardUpdater(train_iter, optimizer, device=-1)\n",
        "trainer = Trainer(updater, (60, 'epoch'), out='result')\n",
        "\n",
        "# Log and print training progress\n",
        "trainer.extend(LogReport())\n",
        "trainer.extend(PrintReport(['epoch', 'main/loss', 'main/accuracy']))\n",
        "trainer.run()"
      ],
      "metadata": {
        "id": "EOa3Bty816Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "PzHPg4Roq3uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageDataset(chainer.dataset.DatasetMixin):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def get_example(self, i):\n",
        "        image = self.data[i]\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Warning: Image at index {i} is None.\")\n",
        "            return None\n",
        "\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        return image.transpose(2, 0, 1)"
      ],
      "metadata": {
        "id": "MUkasM7bzSHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_test(model, test_dataset):\n",
        "    predictions = []\n",
        "    with chainer.using_config('train', False):\n",
        "        for i in range(len(test_dataset)):\n",
        "            test_image = test_dataset[i]\n",
        "            if test_image is not None:\n",
        "                test_image = model.xp.asarray(test_image)\n",
        "                test_image = test_image.reshape((1,) + test_image.shape)\n",
        "                pred = model(test_image)\n",
        "                if pred is not None:\n",
        "                    probabilities = chainer.cuda.to_cpu(pred.array[0])\n",
        "                    predictions.append(probabilities)\n",
        "                else:\n",
        "                    print(f\"Warning: Skipping inference for None prediction at index {i}.\")\n",
        "            else:\n",
        "                print(f\"Warning: Skipping inference for None image at index {i}.\")\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "Q0YjgbPJz5LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TestImageDataset(test_data)\n",
        "\n",
        "model_test = DetectCNN()\n",
        "model_test.train = False\n",
        "\n",
        "test_predictions = predict_on_test(model_test, test_dataset)\n",
        "print(test_predictions)"
      ],
      "metadata": {
        "id": "MrzhttHe0BNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have ground truth labels for test data\n",
        "true_labels = [label == 1 for label in test_labels]\n",
        "\n",
        "# Convert probabilities to predicted labels\n",
        "predicted_labels = [np.argmax(pred) for pred in test_predictions]\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy on test data: {accuracy}\")"
      ],
      "metadata": {
        "id": "86mw5S8K2GpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, pred in enumerate(test_predictions):\n",
        "    print(f\"Example {i + 1} - Predicted Probabilities: {pred}\")"
      ],
      "metadata": {
        "id": "5I82Dwm12RcJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}